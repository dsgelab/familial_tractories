{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from statsmodels.tools.sm_exceptions import PerfectSeparationError\n",
    "from sklearn.preprocessing import StandardScaler#, MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "date = '20240228'\n",
    "OUTCOME = 'T1D_STRICT'\n",
    "SEED = 4\n",
    "covariates = ['PC'+str(i) for i in range(1, 11)] + ['sex', 'age']\n",
    "eps_sig = ['E4_GRAVES_STRICT','D3_ANAEMIA_B12_DEF','E4_HYTHY_AI_STRICT',\n",
    "           'K11_COELIAC','M13_SJOGREN','M13_RHEUMA','T1D_STRICT']\n",
    "eps_dict = {\n",
    "    'D3_AIHA_OTHER':'Autoimmune hemolytic anemia',\n",
    "    'D3_ALLERGPURPURA':'Allergic purpura',\n",
    "    'D3_ANAEMIA_B12_DEF':'Vitamin B12 deficiency anaemia',\n",
    "    'D3_ITP':'Idiopathic thrombocytopenic purpura',\n",
    "    'CHIRBIL_PRIM':'Primary biliary cholangitis',\n",
    "    'K11_COELIAC':'Coeliac disease',\n",
    "    'K11_IBD':'Inflammatory bowel disease',\n",
    "    'N14_IGA_NEPHROPATHY':'IgA nephropathy',\n",
    "    'M13_MCTD':'Mixed connective tissue disease',\n",
    "    'M13_RHEUMA':'Rheumatoid arthritis',\n",
    "    'M13_SJOGREN':'Sj√∂gren syndrome',\n",
    "    'M13_SYSTSLCE':'Systemic sclerosis',\n",
    "    'M13_WEGENER':'Wegener granulomatosis',\n",
    "    'SLE_FG':'Systemic lupus erythematosus',\n",
    "    'G6_GUILBAR':'Guillain-Barre syndrome',\n",
    "    'G6_MS':'Multiple Sclerosis',\n",
    "    'G6_MYASTHENIA':'Myasthenia gravis',\n",
    "    'L12_ALOPECAREATA':'Alopecia areata',\n",
    "    'L12_PSORIASIS':'Psoriasis',\n",
    "    'L12_VITILIGO':'Vitiligo',\n",
    "    'E4_ADDISON':'Adrenocortical insufficiency',\n",
    "    'E4_GRAVES_STRICT':'Autoimmune hyperthyroidism',\n",
    "    'E4_HYTHY_AI_STRICT':'Autoimmune hypothyroidism',\n",
    "    'T1D_STRICT':'Type 1 diabetes'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "genes = ['A*01:01', 'A*01:02', 'A*02:01', 'A*02:02', 'A*02:03', 'A*02:05', 'A*02:06', 'A*02:07', 'A*02:17', 'A*03:01', 'A*11:01',\n",
    " 'A*23:01', 'A*24:02', 'A*25:01', 'A*26:01', 'A*29:01', 'A*29:02', 'A*30:01', 'A*30:02', 'A*31:01', 'A*32:01', 'A*33:01',\n",
    " 'A*33:03', 'A*33:05', 'A*68:01', 'A*69:01', 'A*68167', 'C*01:02', 'C*02:02', 'C*03:02', 'C*03:03', 'C*03:04', 'C*04:01',\n",
    " 'C*04:06', 'C*05:01', 'C*06:02', 'C*07:01', 'C*07:02', 'C*07:04', 'C*08:02', 'C*12:02', 'C*12:03', 'C*14:02', 'C*15:02',\n",
    " 'C*15:05', 'C*16:01', 'C*16:02', 'C*17:01', 'C*17:03', 'C*03327', 'B*07:01', 'B*07:02', 'B*08:01', 'B*13:01', 'B*13:02',\n",
    " 'B*14:01', 'B*14:02', 'B*15:01', 'B*15:16', 'B*15:17', 'B*18:01', 'B*27:02', 'B*27:05', 'B*35:01', 'B*35:02', 'B*35:03',\n",
    " 'B*35:08', 'B*37:01', 'B*38:01', 'B*39:01', 'B*39:06', 'B*39:24', 'B*40:01', 'B*40:02', 'B*41:01', 'B*41:02', 'B*44:02',\n",
    " 'B*44:03', 'B*44:27', 'B*45:01', 'B*46:01', 'B*47:01', 'B*49:01', 'B*50:01', 'B*51:01', 'B*52:01', 'B*55:01', 'B*56:01',\n",
    " 'B*57:01', 'B*58:01', 'DRB3*01:01', 'DRB4*01:01', 'DRB5*01:01', 'DRB3*02:02', 'DRB4*01:03', 'DRB5*01:02', 'DRB3*03:01',\n",
    " 'DRB4*01:03N', 'DRB5*02:02', 'DRB1*01:01', 'DRB1*01:02', 'DRB1*01:03', 'DRB1*03:01', 'DRB1*04:01', 'DRB1*04:02', 'DRB1*04:03',\n",
    " 'DRB1*04:04', 'DRB1*04:05', 'DRB1*04:07', 'DRB1*04:08', 'DRB1*07:01', 'DRB1*07:03', 'DRB1*08:01', 'DRB1*08:02', 'DRB1*08:03',\n",
    " 'DRB1*09:01', 'DRB1*10:01', 'DRB1*11:01', 'DRB1*11:03', 'DRB1*11:04', 'DRB1*12:01', 'DRB1*13:01', 'DRB1*13:02', 'DRB1*13:03',\n",
    " 'DRB1*13:05', 'DRB1*13:32', 'DRB1*14:01', 'DRB1*14:02', 'DRB1*14:54', 'DRB1*15:01', 'DRB1*15:02', 'DRB1*16:01', 'DQA1*03:02',\n",
    " 'DQA1*01:01', 'DQA1*03:03', 'DQA1*01:02', 'DQA1*04:01', 'DQA1*01:03', 'DQA1*04:02', 'DQA1*01:04', 'DQA1*05:01', 'DQA1*01:05',\n",
    " 'DQA1*05:03', 'DQA1*02:01', 'DQA1*05:05', 'DQA1*03:01', 'DQA1*06:01', 'DQB1*02:01', 'DQB1*02:02', 'DQB1*03:01', 'DQB1*03:02',\n",
    " 'DQB1*03:03', 'DQB1*03:04', 'DQB1*03:05', 'DQB1*04:02', 'DQB1*05:01', 'DQB1*05:02', 'DQB1*05:03', 'DQB1*06:01', 'DQB1*06:02',\n",
    " 'DQB1*06:03', 'DQB1*06:04', 'DQB1*06:09', 'DPB1*01:01', 'DPB1*02:01', 'DPB1*02:02', 'DPB1*03:01', 'DPB1*04:01', 'DPB1*04:02',\n",
    " 'DPB1*04.02', 'DPB1*05:01', 'DPB1*06:01', 'DPB1*09:01', 'DPB1*10:01', 'DPB1*11:01', 'DPB1*13:01', 'DPB1*14:01', 'DPB1*15:01',\n",
    " 'DPB1*16:01', 'DPB1*17:01', 'DPB1*19:01', 'DPB1*20:01', 'DPB1*23:01', 'DPB1*25:01', 'DPB1*31:01', 'DPB1*34:01', 'DPB1*105:01']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load all the individuals\n",
    "events = pd.read_csv('finngen_R11/phenotype_1.0/data/finngen_R11_minimum_extended_1.0.txt.gz', sep='\\t')\n",
    "print('at beginning', len(events))\n",
    "events = events[(events.movedabroad.isna())&(events.regionofbirth != 9999)]\n",
    "events = events[['FINNGENID', 'COHORT']].rename(columns={'FINNGENID':'finngen_id', 'COHORT':'source'})\n",
    "print('now', len(events))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hla_df = pd.read_csv('hla_R11.csv')\n",
    "phenos = pd.read_csv('phenos.csv')\n",
    "hla_df = phenos.rename(columns={'FINNGENID':'finngen_id'}).merge(hla_df, 'inner')\n",
    "hla_df = hla_df.merge(events, 'inner')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in eps_dict.keys():\n",
    "    hla_df[i] = np.select([(hla_df[i+'_onset'].isna()), (~hla_df[i+'_onset'].isna())], [0, 1])\n",
    "\n",
    "hla_df['sex'] = np.select([(hla_df.SEX == 'female'), (hla_df.SEX == 'male')], [1, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mop = pd.read_csv('finngen_R11/phenotype_1.0/data/finngen_omop/finngen_R11_person.csv', sep='\\t')\n",
    "mop = mop[['person_source_value', 'birth_datetime']].rename(columns={'person_source_value':'finngen_id'})\n",
    "hla_df = hla_df.merge(mop, 'left')\n",
    "hla_df['birth_yr'] = hla_df['birth_datetime'].str.split('-').str[0].astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load family pedigree data\n",
    "fam = pd.read_csv('finngen_R11/kinship_1.0/data/finngen_R11_pedigree.fam', sep='\\t', header=None)\n",
    "fam.columns = ['family_id', 'finngen_id', 'father_id', 'mother_id', 'sex', 'phenotype']\n",
    "fam_pa = fam[fam.mother_id.isin(hla_df.finngen_id)&fam.father_id.isin(hla_df.finngen_id)]\n",
    "\n",
    "test_df = hla_df[hla_df.finngen_id.isin(list(set(fam_pa.finngen_id.tolist()+fam_pa.father_id.tolist()+\\\n",
    "                                                 fam_pa.mother_id.tolist())))]\n",
    "train_df = hla_df[~hla_df.finngen_id.isin(test_df.finngen_id)]\n",
    "print('train_df', len(train_df), 'test_df', len(test_df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t1d_contr_df = test_df[(test_df.source == 'THL BIOBANK T1D')&(test_df.T1D_STRICT == 0)]\n",
    "test_df1 = test_df[~test_df.finngen_id.isin(t1d_contr_df.finngen_id)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Individual PGS\n",
    "### HLA PGS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eps_selected = ['T1D_STRICT', 'E4_HYTHY_AI_STRICT', 'M13_RHEUMA', 'SLE_FG',\n",
    "                'K11_COELIAC', 'L12_PSORIASIS', 'K11_IBD', 'G6_MS']\n",
    "full_df = hla_df[['finngen_id']+covariates+genes+eps_selected]\n",
    "full_df.sex = full_df.sex.astype(int)\n",
    "\n",
    "for ep in eps_selected:\n",
    "    try:\n",
    "        prs = pd.read_csv('/home/ivm/Desktop/t1d/sandbox_prs_r11/'+ep+'.no_regions.sscore', sep='\\t')\n",
    "        prs = prs.sort_values('SCORE1_AVG')\n",
    "        prs = prs[['IID', 'SCORE1_AVG']].rename(columns={'IID':'finngen_id', 'SCORE1_AVG':'non_'+ep})\n",
    "        full_df = full_df.merge(prs, 'left')\n",
    "    except:\n",
    "        print(ep)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for ep in eps_selected+['M13_MCTD', 'E4_ADDISON']:\n",
    "    full_df['hla_'+ep] = full_df[genes].to_numpy() @ weight_df_dict[ep]\n",
    "\n",
    "full_df = full_df[['finngen_id']+covariates+eps_selected+['non_'+ep for ep in eps_selected]+\\\n",
    "    ['hla_'+ep for ep in eps_selected]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_res_pcor = pd.read_csv('/home/ivm/Desktop/t1d/full_res_pcor_'+date+'.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for ep in eps_selected:\n",
    "    print(ep, full_df['non_'+ep].corr(full_df['hla_'+ep]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eps_selected_weights1 = {}\n",
    "eps_selected_weights2 = {}\n",
    "\n",
    "for i, row in full_res_pcor.iterrows():\n",
    "    ep = row.endpoint\n",
    "    a = round(row.pcor_hla1/(row.pcor_hla1+row.pcor_non1), 2)\n",
    "    b = round(row.pcor_non1/(row.pcor_hla1+row.pcor_non1), 2)\n",
    "    eps_selected_weights1[ep] = (a, b)\n",
    "    non2 = round(np.abs(row.pcor_non1)/(np.abs(row.pcor_hla1)+np.abs(row.pcor_non1)), 2)\n",
    "    if non2 < 0:\n",
    "        eps_selected_weights2[ep] = (1, 0)\n",
    "    else:\n",
    "        hla2 = round(np.abs(row.pcor_hla1)/(np.abs(row.pcor_hla1)+np.abs(row.pcor_non1)), 2)\n",
    "        eps_selected_weights2[ep] = (hla2, non2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eps_selected_weights3 = {}\n",
    "for k,v in eps_selected_weights1.items():\n",
    "    if k == 'T1D_STRICT':\n",
    "        eps_selected_weights3['k'] = (0.67, 0.33)\n",
    "    else:\n",
    "        a = v[0]*0.67/(v[0]*0.67+v[1]*0.33)\n",
    "        b = v[1]*0.67/(v[0]*0.67+v[1]*0.33)\n",
    "        eps_selected_weights3['k'] = (round(a, 2), round(b, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for ep in eps_selected:\n",
    "    try:\n",
    "        prs = pd.read_csv('/home/ivm/Desktop/t1d/sandbox_prs_r11/'+ep+'.sscore', sep='\\t')\n",
    "        prs = prs.sort_values('SCORE1_AVG')\n",
    "        prs = prs[['IID', 'SCORE1_AVG']].rename(columns={'IID':'finngen_id', 'SCORE1_AVG':'prscs_'+ep})\n",
    "        full_df = full_df.merge(prs, 'left')\n",
    "    except:\n",
    "        print(ep)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eps_excluded = [i for i in eps_dict.keys() if i not in eps_selected]\n",
    "full_df = full_df.merge(hla_df[['finngen_id']+eps_excluded], 'left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ep1, ep2 = 'M13_MCTD', 'E4_ADDISON'\n",
    "temp_df = full_df[['finngen_id']+covariates+[i+ep for i in ['', 'non_', 'hla_', 'prscs_']\n",
    "                                             for ep in eps_selected]+eps_excluded+['hla_'+ep1,'hla_'+ep2]]\n",
    "df = fam_pa.iloc[:, :-2].merge(temp_df, 'left')\n",
    "\n",
    "temp_df = full_df[['finngen_id']+[i+ep for i in ['', 'non_', 'hla_', 'prscs_']\n",
    "                                  for ep in eps_selected]+eps_excluded+['hla_'+ep1,'hla_'+ep2]]\n",
    "temp_df.columns = ['father_id']+[i+ep for i in ['fa_', 'fa_non_', 'fa_hla_', 'fa_prscs_']\n",
    "                                 for ep in eps_selected]+eps_excluded+['fa_hla_'+ep1,'fa_hla_'+ep2]\n",
    "df = df.merge(temp_df, 'left')\n",
    "\n",
    "temp_df = full_df[['finngen_id']+[i+ep for i in ['', 'non_', 'hla_', 'prscs_']\n",
    "                                  for ep in eps_selected]+eps_excluded+['hla_'+ep1,'hla_'+ep2]]\n",
    "temp_df.columns = ['father_id']+[i+ep for i in ['fa_', 'fa_non_', 'fa_hla_', 'fa_prscs_']\n",
    "                                 for ep in eps_selected]+eps_excluded+['fa_hla_'+ep1,'fa_hla_'+ep2]\n",
    "df = df.merge(temp_df, 'left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "what = 'improved_'\n",
    "mita = 'full_'\n",
    "shenme = 'prscs'\n",
    "for ep in eps_selected:\n",
    "    # add mid-parent non-HLA PGSs\n",
    "    df['pa_non_'+ep] = (df['mo_non_' + ep] + df['fa_non_' + ep]) / 2\n",
    "    # add mid-parent HLA PGSs\n",
    "    df['pa_hla_'+ep] = (df['mo_hla_' + ep] + df['fa_hla_' + ep]) / 2\n",
    "    # add delta between mid-parent PGSs and child's PGS\n",
    "    df['non_delta_'+ep] = df['non_' + ep] - df['pa_non_'+ep]\n",
    "    df['hla_delta_'+ep] = df['hla_' + ep] - df['pa_hla_'+ep]\n",
    "\n",
    "    # add improved full pgs for all\n",
    "    hla_w = eps_selected_weights3[ep][0]\n",
    "    non_w = eps_selected_weights3[ep][1]\n",
    "    df[what+ep] = df['hla_'+ep]*hla_w + df['non_'+ep]*non_w\n",
    "    df['mo_'+what+ep] = df['mo_hla_'+ep]*hla_w + df['mo_non_'+ep]*non_w\n",
    "    df['fa_'+what+ep] = df['fa_hla_'+ep]*hla_w + df['fa_non_'+ep]*non_w\n",
    "    df['pa_'+what+ep] = (df['mo_'+what+ep] + df['fa_'+what+ep]) / 2\n",
    "    df[what+'delta_'+ep] = df[what+ep] - df['pa_'+what+ep]\n",
    "\n",
    "    # add basic full pgs for all\n",
    "    hla_w = eps_selected_weights1[ep][0]\n",
    "    non_w = eps_selected_weights1[ep][1]\n",
    "    df[mita+ep] = df['hla_'+ep]*hla_w + df['non_'+ep]*non_w\n",
    "    df['mo_'+mita+ep] = df['mo_hla_'+ep]*hla_w + df['mo_non_'+ep]*non_w\n",
    "    df['fa_'+mita+ep] = df['fa_hla_'+ep]*hla_w + df['fa_non_'+ep]*non_w\n",
    "    df['pa_'+mita+ep] = (df['mo_'+mita+ep] + df['fa_'+mita+ep]) / 2\n",
    "    df[mita+'delta_'+ep] = df[mita+ep] - df['pa_'+mita+ep]\n",
    "\n",
    "    # add prs-cs for all\n",
    "    df['pa_'+shenme+ep] = (df['mo_'+shenme+ep] + df['fa_'+shenme+ep]) / 2\n",
    "    df[shenme+'delta_'+ep] = df[shenme+ep] - df['pa_'+shenme+ep]\n",
    "\n",
    "for ep in ['M13_MCTD', 'E4_ADDISON']:\n",
    "    df['pa_hla_'+ep] = (df['mo_hla_'+ep] + df['fa_hla_'+ep]) / 2\n",
    "    df['hla_delta_'+ep] = df['hla_'+ep] - df['pa_hla_'+ep]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[~df.pa_non_T1D_STRICT.isna()]\n",
    "family = df.drop(columns='family_id')\n",
    "family.to_csv('family_20240212.csv', index=None)\n",
    "# len(family) = 12563"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mendelian sampling effect"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors = ['crimson', 'silver']\n",
    "width = 0.12\n",
    "ylabel = 'Child - med-parent PGS'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getStatsForPlotting1(data, region, endpoint):\n",
    "    col_delta = region+'_delta_'+endpoint\n",
    "    col_pa = 'pa_'+region+'_'+endpoint\n",
    "    n = len(data)\n",
    "\n",
    "    delta_deviation = data[col_delta]/data[col_pa].std()\n",
    "    mean_deviation = delta_deviation.mean()\n",
    "    sd_deviation = delta_deviation.std()\n",
    "\n",
    "    t_stats = mean_deviation/(sd_deviation/n**.5)\n",
    "    pvalue = t.sf(np.abs(t_stats), n-1)*2\n",
    "\n",
    "    if pvalue < 0.01:\n",
    "        p = f'P = {pvalue:.2e}'\n",
    "    else:\n",
    "        p = 'P = '+str(round(pvalue, 2))\n",
    "    boolean = True if pvalue <= 0.05 else False\n",
    "    return [mean_deviation, mean_deviation-1.96*sd_deviation/np.sqrt(n), mean_deviation+1.96*sd_deviation/np.sqrt(n),\n",
    "            p, boolean, pvalue]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for ep in eps_selected:\n",
    "    # remove all children with affacted parent(s)\n",
    "    t1d_prs_2 = family[(family['mo_'+ep] == 0)&(family['fa_'+ep] == 0)]\n",
    "    # num of children 2115 -> 2115\n",
    "    # in which 772 affacted children, 1304 unaffacted children\n",
    "    t1d_prs_2 = t1d_prs_2[['finngen_id', 'father_id', 'mother_id', 'T1D_STRICT',\n",
    "                           'non_delta_'+ep, 'hla_delta_'+ep, 'pa_non_'+ep, 'pa_hla_'+ep]]\n",
    "\n",
    "    af_df = t1d_prs_2[t1d_prs_2.T1D_STRICT == 1]\n",
    "    uf_df = t1d_prs_2[t1d_prs_2.T1D_STRICT == 0]\n",
    "    uf_df = uf_df[uf_df.father_id.isin(af_df.father_id)&uf_df.mother_id.isin(af_df.mother_id)]\n",
    "\n",
    "    cols = af_df.columns.tolist()+['outcome','group']\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    group_n = 0\n",
    "    for i,row in tqdm.tqdm(af_df.iterrows()):\n",
    "        temp_df = uf_df[(uf_df.father_id == row.father_id)&(uf_df.mother_id == row.mother_id)]\n",
    "        if len(temp_df) > 0:\n",
    "            group_n += 1\n",
    "            row['outcome'] = 1\n",
    "            row['group'] = group_n\n",
    "            df = df.append(row, ignore_index=True)\n",
    "            temp_df['outcome'] = 0\n",
    "            temp_df['group'] = group_n\n",
    "            df = pd.concat([df,temp_df])\n",
    "    print('affacted siblings',len(df[df.outcome == 1]))\n",
    "    print('unaffacted siblings',len(df[df.outcome == 0]))\n",
    "\n",
    "    plt.figure(figsize=(3, 4))\n",
    "    plt.box(False)\n",
    "    plt.grid()\n",
    "    regions = ['hla','non']\n",
    "    data = df\n",
    "    outcome=ep\n",
    "\n",
    "    for i in [0,1]:\n",
    "        af = getStatsForPlotting1(data[data.outcome == 1], regions[i], ep)\n",
    "        print(regions[i], ep, af)\n",
    "        plt.plot((i-width, i-width), (af[1], af[2]), color=colors[0])\n",
    "        plt.plot(i-width, af[0], 's', color=colors[0])\n",
    "        plt.annotate(af[3], (i-width+.05, af[2]), size=9, color='black')\n",
    "        # plt.annotate(af[3], (i-width-.3, af[2]*1.1), size=9, color='black')\n",
    "\n",
    "        un = getStatsForPlotting1(data[data.outcome == 0], regions[i], ep)\n",
    "        print(regions[i], ep, un)\n",
    "        plt.plot((i+width, i+width), (un[1], un[2]), color=colors[1])\n",
    "        plt.plot(i+width, un[0], 's', color=colors[1])\n",
    "        plt.annotate(un[3], (i+width+.05, un[2]), size=9, color='black')\n",
    "\n",
    "    plt.xticks(range(2), ['HLA','non-HLA'])#, rotation=90)\n",
    "    plt.ylabel(ylabel, size=12)\n",
    "    plt.xlabel(eps_dict[outcome], size=12)\n",
    "    plt.xlim([-0.6,1.6])\n",
    "    plt.axhline(y=0.0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}